{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import string\n",
    "import operator\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from matplotlib.pyplot import figure\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "inverted_index = {}\n",
    "weight_dict = {}\n",
    "train_label_count = {}\n",
    "word_idf_scores = {}\n",
    "threshold = 10\n",
    "doc_count = 0\n",
    "train_doc_ids = []\n",
    "whole_body = []\n",
    "testing_labels = [\"Treatment\", \"Diagnosis\", \"Prevention\", \"Mechanism\", \"Transmission\", \"Epidemic Forecasting\", \"Case Report\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Document and Stopwords\n",
    "df = pd.read_csv('BC7-LitCovid-Train.csv')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the Documents\n",
    "df[\"label\"] = df['label'].str.lower()\n",
    "df[\"title\"] = df['title'].str.lower()\n",
    "df[\"abstract\"] = df['abstract'].str.lower()\n",
    "\n",
    "df[\"title\"] = df['title'].str.replace('[^\\w\\s]','')\n",
    "df[\"abstract\"] = df['abstract'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "df[\"label\"] = df['label'].str.replace('\\d+', '')\n",
    "df['title'] = df['title'].str.replace('\\d+', '')\n",
    "df['abstract'] = df['abstract'].str.replace('\\d+', '')\n",
    "\n",
    "df[\"title\"] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "df[\"abstract\"] = df['abstract'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dev spilitting\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(df[['pmid', 'title', 'abstract']], df[['pmid', 'label']],  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping document counts\n",
    "doc_count = len(X_train.index)\n",
    "dev_doc_count = len(X_dev.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting labels and sort index\n",
    "y_train = y_train.sort_index()\n",
    "y_dev = y_dev.sort_index()\n",
    "\n",
    "y_train['label'] = y_train['label'].str.split(';')\n",
    "y_dev['label'] = y_dev['label'].str.split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of labels\n",
    "for label in y_train['label']:\n",
    "    for item in label:\n",
    "        if item in train_label_count:\n",
    "            train_label_count[item]+=1\n",
    "        else:\n",
    "            train_label_count[item]={}\n",
    "            train_label_count[item]=1\n",
    "train_label_count = {k: v for k, v in sorted(train_label_count.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occurences of training labels\n",
    "labels = list(train_label_count.keys())\n",
    "occurrences = list(train_label_count.values())\n",
    "\n",
    "plt.bar(range(len(train_label_count)), occurrences, tick_label=labels)\n",
    "\n",
    "plt.title(\"# of occurrences of labels in the training data\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Occurrences\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12.5, 7.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort processing data index\n",
    "X_train = X_train.sort_index()\n",
    "X_dev = X_dev.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping document IDs\n",
    "train_doc_ids = X_train[\"pmid\"]\n",
    "dev_doc_ids = X_dev[\"pmid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining informational data\n",
    "X_train['title/abstract'] = X_train['title'] + \" \" + X_train['abstract']\n",
    "X_dev['title/abstract'] = X_dev['title'] + \" \" + X_dev['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting data to get all informational words\n",
    "X_train['title/abstract'] = [item.split() for item in X_train['title/abstract']]\n",
    "X_dev['title/abstract'] = [item.split() for item in X_dev['title/abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the whole words\n",
    "for i in X_train['title/abstract']:\n",
    "    whole_body += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the most common words\n",
    "whole_body_copy = whole_body.copy()\n",
    "common_words = []\n",
    "common_words_occ = []\n",
    "for i in range(1,11):\n",
    "    most_common, num_most_common = Counter(whole_body_copy).most_common(1)[0]\n",
    "    common_words.append(most_common)\n",
    "    common_words_occ.append(num_most_common)\n",
    "    whole_body_copy = list(filter(lambda a: a != most_common, whole_body_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occurences of training words\n",
    "plt.bar(range(len(common_words)), common_words_occ, tick_label=common_words)\n",
    "\n",
    "plt.title(\"10 Most Common Words\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Occurrence\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12.5, 7.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurences of words\n",
    "vocab_keys = Counter(whole_body).keys()\n",
    "vocab_values = Counter(whole_body).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns a dictionary which is the inverted version of previous one\n",
    "# this dictionary has indexes as words not ids\n",
    "def inverted_index_creation(array):\n",
    "    new_dictionary = {}\n",
    "    for idx in array.keys():\n",
    "        ids = train_doc_ids[idx]\n",
    "        for word in array[idx]:\n",
    "            if(word not in new_dictionary):\n",
    "                dct = {}\n",
    "                dct[ids] = 1\n",
    "                new_dictionary[word] = dct\n",
    "            else:\n",
    "                current_word_counts = new_dictionary[word]\n",
    "                if(ids in current_word_counts):\n",
    "                    current_word_counts[ids] += 1\n",
    "                else:\n",
    "                    current_word_counts[ids] = 1\n",
    "                new_dictionary[word] = current_word_counts\n",
    "    for w in list(new_dictionary.keys()):\n",
    "        if len(new_dictionary[w]) < threshold:\n",
    "            del new_dictionary[w]\n",
    "    return new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf(query_word, query):\n",
    "    if query_word in query:\n",
    "        return (1 + np.log10(query.count(query_word)))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that has parameters query word and returns the idf value of it\n",
    "def calculate_idf(query_word):\n",
    "    if(query_word in inverted_index):\n",
    "        document_freq = len(inverted_index[query_word])\n",
    "        return np.log10(np.divide(doc_count, document_freq))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that has a parameter as dictionary that has key as document id and value as words\n",
    "# returns a dictionary that has key as document id and value\n",
    "def calc_tfidf(bodies):\n",
    "    weigth_dict = {}\n",
    "    for idx in bodies.keys():\n",
    "        dict_tfidf_value = {}\n",
    "        for word in inverted_index:\n",
    "            if word not in dict_tfidf_value:\n",
    "                dict_tfidf_value[word] = np.multiply(word_idf_scores[word], calculate_tf(word, bodies[idx]))\n",
    "        weigth_dict[idx] = dict_tfidf_value\n",
    "    return weigth_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Inverted Index Dictionary\n",
    "inverted_index = inverted_index_creation(X_train['title/abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Inverted Index DataFrame\n",
    "inverted_index_df = pd.DataFrame.from_dict(inverted_index, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping all idf scores of words in Inverted Index\n",
    "word_idf_scores = {word: calculate_idf(word) for word in inverted_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating tfidf weigths of training words\n",
    "weight_dict = calc_tfidf(X_train['title/abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping all tfidf scores of training words in DataFrame\n",
    "weight_df = pd.DataFrame.from_dict(weight_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating tfidf weigths of Development words\n",
    "weight_dict_dev = calc_tfidf(X_dev['title/abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Keeping all tfidf scores of Development words in DataFrame\n",
    "weight_df_dev = pd.DataFrame.from_dict(weight_dict_dev, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan values of training DataFrame changes to 0 and sort index\n",
    "weight_df = weight_df.fillna(0)\n",
    "weight_df = weight_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan values of Development DataFrame changes to 0 and sort index\n",
    "weight_df_dev = weight_df_dev.fillna(0)\n",
    "weight_df_dev = weight_df_dev.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating OneVsRest Classifier\n",
    "classifier = OneVsRestClassifier(LinearSVC(random_state=0, max_iter=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizing the labels and fitting\n",
    "mlb = MultiLabelBinarizer()\n",
    "multilabel_y = mlb.fit_transform(y_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model for the classifier\n",
    "model = classifier.fit(weight_df, multilabel_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Development data using the model\n",
    "pred = model.predict(weight_df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_inv = mlb.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = mlb.fit_transform(y_dev['label'])\n",
    "actual_inv = mlb.inverse_transform(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_result_df = pd.DataFrame(actual, columns = sorted(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result_df = pd.DataFrame(pred, columns = sorted(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_result_df.to_csv('pred_result_df.csv', sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_result_df.to_csv('actual_result_df.csv', sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = multilabel_confusion_matrix(actual, pred)\n",
    "print(cm)\n",
    "print(classification_report(actual, pred, target_names = sorted(testing_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence(pred_labels, label_set):\n",
    "    d = defaultdict(int)\n",
    "    vocab = set()\n",
    "    for label in label_set:\n",
    "        vocab.add(label)\n",
    "    for labels in pred_labels:\n",
    "        # iterate over sentences\n",
    "        for i in range(len(labels)):\n",
    "            token = labels[i]\n",
    "            next_token = labels[i+1 : ]\n",
    "            for t in next_token:\n",
    "                key = tuple( sorted([t, token]) )\n",
    "                d[key] += 1\n",
    "    \n",
    "    # formulate the dictionary into dataframe\n",
    "    vocab = sorted(vocab) # sort vocab\n",
    "    df = pd.DataFrame(data=np.zeros((len(vocab), len(vocab)), dtype=np.int16),\n",
    "                      index=vocab,\n",
    "                      columns=vocab)\n",
    "    for key, value in d.items():\n",
    "        df.at[key[0], key[1]] = value\n",
    "        df.at[key[1], key[0]] = value\n",
    "    return df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [\"treatment\", \"diagnosis\", \"prevention\", \"mechanism\", \"transmission\", \"epidemic forecasting\", \"case report\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_matrix = co_occurrence(pred_inv, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chord(co_occurrence_matrix, all_labels).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining train and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_dev)\n",
    "y_train = y_train.append(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.sort_index()\n",
    "y_train = y_train.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ids = X_train[\"pmid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating an Inverted Index Dictionary\n",
    "inverted_index = inverted_index_creation(X_train['title/abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Inverted Index DataFrame\n",
    "inverted_index_df = pd.DataFrame.from_dict(inverted_index, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping all idf scores of words in Inverted Index\n",
    "word_idf_scores = {word: calculate_idf(word) for word in inverted_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating tfidf weigths of training words\n",
    "weight_dict = calc_tfidf(X_train['title/abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping all tfidf scores of training words in DataFrame\n",
    "weight_df = pd.DataFrame.from_dict(weight_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan values of training DataFrame changes to 0 and sort index\n",
    "weight_df = weight_df.fillna(0)\n",
    "weight_df = weight_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating OneVsRest Classifier\n",
    "classifier = OneVsRestClassifier(LinearSVC(random_state=0, max_iter=100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizing the labels and fitting\n",
    "mlb = MultiLabelBinarizer()\n",
    "multilabel_y = mlb.fit_transform(y_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model for the classifier\n",
    "model = classifier.fit(weight_df, multilabel_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Document and Stopwords\n",
    "df = pd.read_csv('BC7-LitCovid-Dev.csv')\n",
    "\n",
    "# Preprocessing the Documents\n",
    "df[\"label\"] = df['label'].str.lower()\n",
    "df[\"title\"] = df['title'].str.lower()\n",
    "df[\"abstract\"] = df['abstract'].str.lower()\n",
    "\n",
    "df[\"title\"] = df['title'].str.replace('[^\\w\\s]','')\n",
    "df[\"abstract\"] = df['abstract'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "df[\"label\"] = df['label'].str.replace('\\d+', '')\n",
    "df['title'] = df['title'].str.replace('\\d+', '')\n",
    "df['abstract'] = df['abstract'].str.replace('\\d+', '')\n",
    "\n",
    "df[\"title\"] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "df[\"abstract\"] = df['abstract'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "\n",
    "# Train Dev spilitting\n",
    "X_test = pd.DataFrame()\n",
    "X_test['title/abstract'] = df['title'] + \" \" + df['abstract']\n",
    "X_test['title/abstract'] = [item.split() for item in X_test['title/abstract']]\n",
    "y_test = df[['pmid', 'label']]\n",
    "y_test = y_test.sort_index()\n",
    "y_test['label'] = y_test['label'].str.split(';')\n",
    "\n",
    "test_label_count = {}\n",
    "# Calculating number of labels\n",
    "for label in y_test['label']:\n",
    "    for item in label:\n",
    "        if item in test_label_count:\n",
    "            test_label_count[item]+=1\n",
    "        else:\n",
    "            test_label_count[item]={}\n",
    "            test_label_count[item]=1\n",
    "test_label_count = {k: v for k, v in sorted(test_label_count.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occurences of training labels\n",
    "labels = list(test_label_count.keys())\n",
    "occurrences = list(test_label_count.values())\n",
    "\n",
    "plt.bar(range(len(test_label_count)), occurrences, tick_label=labels)\n",
    "\n",
    "plt.title(\"# of occurrences of labels in the test data\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Occurrences\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12.5, 7.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the whole words\n",
    "whole_body = []\n",
    "for i in X_test['title/abstract']:\n",
    "    whole_body += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_body_copy = whole_body.copy()\n",
    "common_words = []\n",
    "common_words_occ = []\n",
    "for i in range(1,11):\n",
    "    most_common, num_most_common = Counter(whole_body_copy).most_common(1)[0]\n",
    "    common_words.append(most_common)\n",
    "    common_words_occ.append(num_most_common)\n",
    "    whole_body_copy = list(filter(lambda a: a != most_common, whole_body_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occurences of training words\n",
    "plt.bar(range(len(common_words)), common_words_occ, tick_label=common_words)\n",
    "\n",
    "plt.title(\"10 Most Common Words\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Occurence\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12.5, 7.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurences of words\n",
    "vocab_keys = Counter(whole_body).keys()\n",
    "vocab_values = Counter(whole_body).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculating tfidf weigths of Development words\n",
    "weight_dict_test = calc_tfidf(X_test['title/abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping all tfidf scores of Development words in DataFrame\n",
    "weight_df_test = pd.DataFrame.from_dict(weight_dict_test, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan values of Development DataFrame changes to 0 and sort index\n",
    "weight_df_test = weight_df_test.fillna(0)\n",
    "weight_df_test = weight_df_test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Development data using the model\n",
    "pred = model.predict(weight_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = mlb.fit_transform(y_test['label'])\n",
    "actual_inv = mlb.inverse_transform(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = multilabel_confusion_matrix(actual, pred)\n",
    "print(cm)\n",
    "print(classification_report(actual, pred, target_names = sorted(testing_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
